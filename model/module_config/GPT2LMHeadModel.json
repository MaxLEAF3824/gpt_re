{
    "n_layer" : "config.num_hidden_layers",
    "block_module_tmp": "transformer.h[{}]",
    "mlp_module_tmp": "transformer.h[{}].mlp",
    "attn_module_tmp": "transformer.h[{}].attn",
    "ln_1_module_tmp": "transformer.h[{}].ln_1",
    "ln_2_module_tmp": "transformer.h[{}].ln_2",
    "ln_f_module": "transformer.ln_f",
    "lm_head_module": "lm_head",
    "embedding_module": "transformer.wte"
}