{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from model.model_interface import LLM\n",
    "from dataset.knowns import Knowns\n",
    "import torch.utils.data as tud\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import torch.nn.functional as F\n",
    "from utils.gpthook import TraceDict\n",
    "import os \n",
    "import random\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM Config\n",
    "llm_config = {\n",
    "    \"model_name\": \"gpt2\",\n",
    "}\n",
    "\n",
    "# Dataset config\n",
    "dl_config = {\n",
    "    \"batch_size\": 1,\n",
    "    \"num_workers\": 1,\n",
    "}\n",
    "data_dir= \"data\"\n",
    "size = 100\n",
    "\n",
    "# Trainer config\n",
    "trainer_config = {\n",
    "    \"precision\" : \"16-mixed\",\n",
    "    \"accelerator\" : \"auto\",\n",
    "    \"devices\" : 1,\n",
    "}\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 100 elements\n"
     ]
    }
   ],
   "source": [
    "mt = LLM(**llm_config)\n",
    "dst = Knowns(data_dir, mt.tokenizer, size)\n",
    "dl = tud.DataLoader(dst, **dl_config, collate_fn=dst.collate_fn)\n",
    "trainer = pl.Trainer(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_comp_flow(mt:LLM, batch:tuple, comp_key, comp_kind):\n",
    "    \"\"\"batch_size equal 1\"\"\"\n",
    "    model, tokenizer, device = mt.model, mt.tokenizer, mt.device\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_tokens = [[tokenizer.decode([t]) for t in seq] for seq in input_ids]\n",
    "    \n",
    "    # get clean td\n",
    "    with torch.no_grad(), TraceDict(mt.model, device=\"cpu\") as clean_td:\n",
    "        logits = mt(input_ids, attention_mask=attention_mask, output_attentions=True)['logits'] # [bsz, seq, vocab]\n",
    "    \n",
    "    clean_prob = F.softmax(logits, dim=-1)\n",
    "    gt_idx = torch.argmax(clean_prob[:,-1,:], dim=-1)\n",
    "    answers = [mt.tokenizer.decode(gt_idx)]\n",
    "    gt_prob = clean_prob[:,-1,gt_idx]\n",
    "    \n",
    "    x0 = clean_td[\"block_0\"].input\n",
    "    table = []\n",
    "    attn_weight_diff = []\n",
    "    for layer in range(1, model.config.n_layer):\n",
    "        if comp_key == \"attn\":\n",
    "            comp = clean_td[f\"{comp_key}_{layer - 1}\"].output[0] \n",
    "        else:\n",
    "            comp = clean_td[f\"{comp_key}_{layer - 1}\"].output\n",
    "        comp = comp.to(device)\n",
    "        column = []\n",
    "        for t_idx in range(len(inp['input_ids'][0])):\n",
    "            prob, td = trace_comp_patch(model, inp, x0, layer, [t_idx], comp, comp_kind)\n",
    "            column.append(gt_prob - prob[:,-1,gt_idx])\n",
    "        column = torch.vstack(column)\n",
    "        table.append(column)\n",
    "        # corrupt all tokens\n",
    "        t_idxs = list(range(len(inp['input_ids'][0])))\n",
    "        prob, td = trace_comp_patch(model, inp, x0, layer, t_idxs, comp, comp_kind, output_attentions=True)\n",
    "        attn_weight_o, attn_weight_fixed = td[f'attn_{layer}'].output[2]\n",
    "        device2 = attn_weight_fixed.device\n",
    "        # pdb.set_trace()\n",
    "        attn_weight_diff.append((attn_weight_o-attn_weight_fixed).abs().sum(dim=-1).sum(dim=-1))\n",
    "    attn_weight_diff = torch.vstack(attn_weight_diff)\n",
    "    table = torch.stack(table).squeeze()\n",
    "    return {\"table\":table.transpose(0,1).cpu(),\n",
    "            \"comp_key\":comp_key,\n",
    "            \"comp_kind\":comp_kind,\n",
    "            \"input_tokens\": input_tokens,  \n",
    "            \"answer\":answers,\n",
    "            \"attn_weight_diff\":attn_weight_diff.cpu()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "/nvme/yangyuchen1/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, predict_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee62c154ffd54a8c8f8cb6766c0cab7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = trainer.predict(mt, dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "# launch tensorboard\n",
    "%tensorboard --logdir lightning_logs/ --port 6009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits', 'past_key_values'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0].keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
