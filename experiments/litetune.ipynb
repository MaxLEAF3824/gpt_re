{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71809660c8bd4fb8b027e21a47f590ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Model:', options=(('gpt2', '/nvme/guoyiqiu/coding/huggingf…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 1.84s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a3632ff4c0443f88fbb2088522a7ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost: 56.41s\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import time\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from model.model_interface import LLM\n",
    "import torch.utils.data as tud\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.my_utils import *\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import regex as re\n",
    "from dataset import *\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from typing import Union, List\n",
    "\n",
    "pl.seed_everything(42)\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "\n",
    "\n",
    "model_list = list({\n",
    "    \"gpt2\": \"/nvme/guoyiqiu/coding/huggingface/hub/models--gpt2/snapshots/e7da7f221d5bf496a48136c0cd264e630fe9fcc8\",\n",
    "    \"gpt2_xl\": \"/nvme/guoyiqiu/coding/huggingface/hub/models--gpt2-xl/snapshots/33cdb5c0db5423c1879b1b9f16c352988e8754a8\",\n",
    "    \"llama_7b\": \"/nvme/share/guoyiqiu/llama-7b\",\n",
    "    \"llama_13b\": \"/nvme/share/guoyiqiu/llama-13b\",\n",
    "    \"vicuna_7b\": \"/nvme/share/guoyiqiu/vicuna-7b\",\n",
    "    \"vicuna_13b\": \"/nvme/share/guoyiqiu/vicuna-13b-v1.1\",\n",
    "}.items())\n",
    "\n",
    "llm_config = {\n",
    "    \"optimizer\": \"adamw\",\n",
    "    \"lr\": 1e-4,\n",
    "}\n",
    "\n",
    "hook_config = {\n",
    "    \"retain_output\": True,\n",
    "    \"retain_input\": False,\n",
    "    \"edit_output\": None,\n",
    "    \"clone\": True,\n",
    "    \"float\": True,\n",
    "    \"detach\": True,\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "def init_mt():\n",
    "    global mt\n",
    "    mt = LLM(model_name=mt_dropdown.value, \n",
    "             fp16=precision_tbtn.value == \"half\", \n",
    "             from_pretrained=from_pretrained_cb.value,\n",
    "             **llm_config)\n",
    "\n",
    "\n",
    "def init_modules():\n",
    "    global n_layer\n",
    "    global lm_head\n",
    "    global embedding\n",
    "    global ln_f\n",
    "    global blocks\n",
    "    global ATTN\n",
    "    global MLP\n",
    "    global LN1\n",
    "    global LN2\n",
    "    if \"gpt2\" in mt.model.__class__.__name__.lower():\n",
    "        # gpt2 config\n",
    "        n_layer = mt.model.config.num_hidden_layers\n",
    "        lm_head = mt.model.lm_head\n",
    "        embedding = mt.model.transformer.wte\n",
    "        ln_f = mt.model.transformer.ln_f\n",
    "        blocks = mt.model.transformer.h\n",
    "        ATTN = 'attn'\n",
    "        MLP = 'mlp'\n",
    "        LN1 = 'ln_1'\n",
    "        LN2 = 'ln_2'\n",
    "    elif \"llama\" in mt.model.__class__.__name__.lower():\n",
    "        # llama config\n",
    "        n_layer = mt.model.config.num_hidden_layers\n",
    "        lm_head = mt.model.lm_head\n",
    "        embedding = mt.model.model.embed_tokens\n",
    "        ln_f = mt.model.model.norm\n",
    "        blocks = mt.model.model.layers\n",
    "        ATTN = 'self_attn'\n",
    "        MLP = 'mlp'\n",
    "        LN1 = 'input_layernorm'\n",
    "        LN2 = 'post_self_attn_layernorm'\n",
    "        \n",
    "\n",
    "\n",
    "def init_hook(mt):\n",
    "    mt.clear_hook()\n",
    "    for i in range(n_layer):\n",
    "        mt.add_hook(module=blocks[i], name=f\"block_{i}\", **hook_config)\n",
    "        mt.add_hook(module=getattr(blocks[i], ATTN), name=f\"attn_{i}\", **hook_config)\n",
    "        mt.add_hook(module=getattr(blocks[i], MLP), name=f\"mlp_{i}\", **hook_config)\n",
    "\n",
    "\n",
    "def setup(btn):\n",
    "    time_st = time.time()\n",
    "    btn.description = \"Loading model...\"\n",
    "    init_mt()\n",
    "    btn.description = \"init modules...\"\n",
    "    init_modules()\n",
    "    btn.description = \"init hooks...\"\n",
    "    init_hook(mt)\n",
    "    btn.description = \"Everything is ready.\"\n",
    "    device_tbtn.value = 'cpu'\n",
    "    print(f\"Time cost: {time.time() - time_st:.2f}s\")\n",
    "\n",
    "# setup widgets\n",
    "\n",
    "\n",
    "# model dropdown\n",
    "mt_dropdown = widgets.Dropdown(\n",
    "    options=model_list,\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "from_pretrained_cb = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='from pretrained',\n",
    ")\n",
    "\n",
    "# setup button\n",
    "setup_btn = widgets.Button(\n",
    "    description=\"Setup everything\",\n",
    "    disabled=False,\n",
    ")\n",
    "setup_btn.on_click(setup)\n",
    "\n",
    "# switch deivce\n",
    "device_tbtn = widgets.ToggleButtons(\n",
    "    options=['cpu', f'cuda',],\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def switch_device(change):\n",
    "    device_tbtn.disabled = True\n",
    "    mt.model.to(change.new)\n",
    "    torch.cuda.empty_cache() if change.new == 'cpu' else None\n",
    "    device_tbtn.disabled = False\n",
    "\n",
    "\n",
    "device_tbtn.observe(switch_device, names='value')\n",
    "\n",
    "# switch precision\n",
    "\n",
    "precision_tbtn = widgets.ToggleButtons(\n",
    "    options=['float', 'half'],\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def switch_precision(change):\n",
    "    precision_tbtn.disabled = True\n",
    "    if mt is not None:\n",
    "        mt.model = mt.model.half() if change.new == 'half' else mt.model.float()\n",
    "        init_modules()\n",
    "    precision_tbtn.disabled = False\n",
    "\n",
    "\n",
    "precision_tbtn.observe(switch_precision, names='value')\n",
    "\n",
    "\n",
    "mnt_slider = widgets.IntSlider(\n",
    "    value=128,\n",
    "    min=1,\n",
    "    max=512,\n",
    "    step=1,\n",
    "    description='new token:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d',\n",
    ")\n",
    "\n",
    "input_textarea = widgets.Textarea(\n",
    "    value='',\n",
    "    description='Input:',\n",
    "    layout=widgets.Layout(width='30%', height='250px'),\n",
    "    disabled=False\n",
    ")\n",
    "output_textarea = widgets.Textarea(\n",
    "    value='',\n",
    "    description='Output:',\n",
    "    layout=widgets.Layout(width='30%', height='250px'),\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "submit_btn = widgets.Button(\n",
    "    description=\"generate\",\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "\n",
    "def generate(btn):\n",
    "    input_text = input_textarea.value\n",
    "    max_new_tokens = mnt_slider.value\n",
    "    btn.disabled = True\n",
    "    submit_btn.description = \"Generating...\"\n",
    "    result = mt.generate(input_text, max_new_tokens=max_new_tokens)\n",
    "    btn.disabled = False\n",
    "    submit_btn.description = \"generate\"\n",
    "    output_text = result[0]\n",
    "    output_textarea.value = output_text\n",
    "\n",
    "\n",
    "submit_btn.on_click(generate)\n",
    "\n",
    "control_panel = widgets.HBox([mt_dropdown, from_pretrained_cb ,setup_btn, precision_tbtn, device_tbtn])\n",
    "talk_panel = widgets.HBox([input_textarea, widgets.VBox([mnt_slider, submit_btn]), output_textarea])\n",
    "all_panel = widgets.VBox([control_panel, talk_panel])\n",
    "display(all_panel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LORA Tune MedQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 4194304 || all params: 6742609920 || trainable%: 0.06220594176090199\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=\n",
    ")\n",
    "\n",
    "mt.model = get_peft_model(mt.model, peft_config)\n",
    "mt.model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Some weights of the model checkpoint at THUDM/glm-2b were not used when initializing GLMModel: ['out_proj.weight', 'out_proj.bias', 'dense.bias', 'dense.weight']\n",
      "- This IS expected if you are initializing GLMModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GLMModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "glm = AutoModel.from_pretrained('THUDM/glm-2b',trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLMModel(\n",
       "  (word_embeddings): VocabEmbedding()\n",
       "  (transformer): GLMStack(\n",
       "    (embedding_dropout): Dropout(p=0.1, inplace=False)\n",
       "    (position_embeddings): Embedding(1025, 2048)\n",
       "    (block_position_embeddings): Embedding(1025, 2048)\n",
       "    (layers): ModuleList(\n",
       "      (0-35): 36 x GLMBlock(\n",
       "        (input_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (attention): SelfAttention(\n",
       "          (query_key_value): Linear(in_features=2048, out_features=6144, bias=True)\n",
       "          (attention_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (dense): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "          (output_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (post_attention_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (dense_h_to_4h): Linear(in_features=2048, out_features=8192, bias=True)\n",
       "          (dense_4h_to_h): Linear(in_features=8192, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layernorm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=\n",
    ")\n",
    "\n",
    "md = get_peft_model(glm, peft_config)\n",
    "md.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "bin = torch.load('/nvme/share/guoyiqiu/lora_Book_7B_0508/checkpoint-5200/pytorch_model.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base_model.model.model.layers.0.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.0.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.0.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.1.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.1.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.2.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.2.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.3.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.3.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.4.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.4.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.5.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.5.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.6.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.6.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.7.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.7.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.8.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.8.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.9.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.9.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.10.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.10.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.11.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.11.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.12.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.12.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.13.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.13.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.14.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.14.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.15.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.15.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.16.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.16.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.17.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.17.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.18.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.18.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.19.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.19.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.20.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.20.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.21.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.21.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.22.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.22.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.23.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.23.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.24.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.24.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.25.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.25.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.26.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.26.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.27.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.27.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.28.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.28.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.29.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.29.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.30.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.30.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.31.self_attn.q_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_A.weight\n",
      "torch.Size([8, 4096])\n",
      "torch.float32\n",
      "base_model.model.model.layers.31.self_attn.v_proj.lora_B.weight\n",
      "torch.Size([4096, 8])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "for (k,v) in bin.items():\n",
    "    print(k)\n",
    "    print(v.shape)\n",
    "    print(v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): PeftModelForCausalLM(\n",
       "      (base_model): LoraModel(\n",
       "        (model): LlamaForCausalLM(\n",
       "          (model): LlamaModel(\n",
       "            (embed_tokens): Embedding(32000, 4096, padding_idx=0)\n",
       "            (layers): ModuleList(\n",
       "              (0-31): 32 x LlamaDecoderLayer(\n",
       "                (self_attn): LlamaAttention(\n",
       "                  (q_proj): Linear(\n",
       "                    in_features=4096, out_features=4096, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                  (v_proj): Linear(\n",
       "                    in_features=4096, out_features=4096, bias=False\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.1, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=4096, bias=False)\n",
       "                    )\n",
       "                  )\n",
       "                  (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "                  (rotary_emb): LlamaRotaryEmbedding()\n",
       "                )\n",
       "                (mlp): LlamaMLP(\n",
       "                  (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                  (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "                  (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "                  (act_fn): SiLUActivation()\n",
       "                )\n",
       "                (input_layernorm): LlamaRMSNorm()\n",
       "                (post_attention_layernorm): LlamaRMSNorm()\n",
       "              )\n",
       "            )\n",
       "            (norm): LlamaRMSNorm()\n",
       "          )\n",
       "          (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt.model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lite Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_all(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "def unfreeze_all(model):\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "def set_module_requires_grad(model, layers: Union[int, List[int]], names: Union[str, List[str]], requires_grad: bool):\n",
    "    layers = [layers] if isinstance(layers, int) else layers\n",
    "    names = [names] if isinstance(names, str) else names\n",
    "    for layer in layers:\n",
    "        for name in names:\n",
    "            assert name in [ATTN, MLP, LN1, LN2]\n",
    "            module = getattr(blocks[layer], name)\n",
    "            for param in module.parameters():\n",
    "                param.requires_grad = requires_grad\n",
    "\n",
    "def my_training_step(self, batch, batch_idx):\n",
    "    '''batch: (input_ids, attention_mask, labels) **padding already** '''\n",
    "    input_ids, attention_mask, labels = batch\n",
    "    input_ids = input_ids.unsqueeze(0) if len(input_ids.shape) == 1 else input_ids\n",
    "    attention_mask = attention_mask.unsqueeze(0) if len(attention_mask.shape) == 1 else attention_mask\n",
    "    labels = labels.unsqueeze(0) if len(labels.shape) == 1 else labels\n",
    "    gt_id = labels[0, -1].item()\n",
    "\n",
    "    bsz = input_ids.shape[0]\n",
    "    assert bsz == 1\n",
    "    \n",
    "    def set_require_grad(module, input, output):\n",
    "        ''' output: (bsz, seq_len, hidden_size) '''\n",
    "        with torch.no_grad():\n",
    "            topk_logits, topk_indices = torch.topk(lm_head(ln_f(output[0])), k=10, dim=-1) # [bsz, seq_len, k]\n",
    "        is_important = gt_id in topk_indices\n",
    "        if is_important:\n",
    "            print(f'{module.name} is_important')\n",
    "            # for param in module.parameters():\n",
    "            #     param.requires_grad = True\n",
    "        return output\n",
    "    \n",
    "    self.clear_hook()\n",
    "    hook_config = {\n",
    "        \"retain_output\": False,\n",
    "        \"retain_input\": False,\n",
    "        \"edit_output\": set_require_grad,\n",
    "        \"clone\": False,\n",
    "        \"float\": False,\n",
    "        \"detach\": False,\n",
    "        \"device\": \"cpu\"\n",
    "    }\n",
    "    for i in range(n_layer):\n",
    "        self.add_hook(module=getattr(blocks[i], ATTN), name=f\"attn_{i}\", **hook_config)\n",
    "    print(batch_idx)\n",
    "    res = self(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    \n",
    "    lm_logits = res['logits']\n",
    "    shift_logits = lm_logits[..., :-1, :].contiguous()  # Shift so that tokens < n predict n\n",
    "    shift_labels = labels[..., 1:].contiguous()\n",
    "\n",
    "    if isinstance(res.get('loss'), torch.Tensor):\n",
    "        loss = res['loss']\n",
    "    else:\n",
    "        loss = self.loss_func(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "\n",
    "    acc = self._acc(shift_logits, shift_labels)\n",
    "\n",
    "    self.log('train_loss', loss, on_step=True, on_epoch=True, sync_dist=True, prog_bar=True)\n",
    "    self.log('train_acc', acc, on_step=False, sync_dist=True, on_epoch=True, prog_bar=True)\n",
    "    print(\"\\n\")\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 2887.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1000 elements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bsz = 32\n",
    "\n",
    "# train_dst = MedQA('/nvme/guoyiqiu/coding/datasets/MedQA/data_clean/questions/US/train.jsonl',tokenizer=mt.tokenizer, max_len=512,size=1000)\n",
    "train_dst = CounterFact('/nvme/guoyiqiu/coding/datasets/rome datasets/counterfact.json', mt.tokenizer,size=1000)\n",
    "train_dl = DataLoader(train_dst, batch_size=bsz, shuffle=True, collate_fn=train_dst.collate_fn, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\n",
      "  | Name  | Type                 | Params\n",
      "-----------------------------------------------\n",
      "0 | model | PeftModelForCausalLM | 1.6 B \n",
      "-----------------------------------------------\n",
      "2.5 M     Trainable params\n",
      "1.6 B     Non-trainable params\n",
      "1.6 B     Total params\n",
      "6,240.275 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27bb661b26d44a94b8bd14604c40d0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">16</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 # set_module_requires_grad(mt.model, list(range(n_layer)), ATTN, True)</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 # trainer = pl.Trainer(**trainer_config, logger=WandbLogger(project='tune medqa', name='</span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span>trainer = pl.Trainer(**trainer_config)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>16 trainer.fit(mt, train_dl)                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">train</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">er.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">520</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 517 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 518 │   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 519 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 520 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 521 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 522 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 523 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">44</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 41 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 44 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 45 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 46 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 47 │   │   </span>_call_teardown_hook(trainer)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">train</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">er.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">559</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_fit_impl</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 556 │   │   │   </span>model_provided=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">True</span>,                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 557 │   │   │   </span>model_connected=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.lightning_module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>,                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 558 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 559 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run(model, ckpt_path=ckpt_path)                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 560 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 561 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.stopped                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 562 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.training = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">train</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">er.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">935</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run</span>                                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 932 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 933 │   │   # RUN THE TRAINER</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 934 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 935 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>results = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run_stage()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 936 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 937 │   │   # ----------------------------</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 938 │   │   # POST-Training CLEAN UP</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">train</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">er.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">978</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_run_stage</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 975 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> isolate_rng():                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 976 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._run_sanity_check()                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 977 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.autograd.set_detect_anomaly(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._detect_anomaly):                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 978 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.fit_loop.run()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 979 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 980 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(<span style=\"color: #808000; text-decoration-color: #808000\">f\"Unexpected state {</span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state<span style=\"color: #808000; text-decoration-color: #808000\">}\"</span>)                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 981 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fit_loo</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">p.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">201</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">198 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.done:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">199 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">200 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_advance_start()                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>201 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.advance()                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">202 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_advance_end()                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">203 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._restarting = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">204 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">StopIteration</span>:                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fit_loo</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">p.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">354</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">advance</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">351 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">352 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher.setup(combined_loader)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">353 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer.profiler.profile(<span style=\"color: #808000; text-decoration-color: #808000\">\"run_training_epoch\"</span>):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>354 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.epoch_loop.run(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._data_fetcher)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">355 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">356 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on_advance_end</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">357 │   │   </span>trainer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.trainer                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainin</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">g_epoch_loop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">130</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">128 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">run</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, data_fetcher: _DataFetcher) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">129 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reset()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>130 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.on_run_start(data_fetcher)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">131 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.done:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">132 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">133 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.advance(data_fetcher)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainin</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">g_epoch_loop.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">164</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on_run_start</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.val_loop.batch_progress.total.reset()                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">on_run_start</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, data_fetcher: _DataFetcher) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>164 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(data_fetcher)  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># creates the iterator inside the fetcher</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">165 │   │   # add the previous `fetched` value to properly track `is_last_batch` with no pre</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">166 │   │   </span>data_fetcher.fetched += <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.batch_progress.current.ready                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">167 │   │   </span>data_fetcher._start_profiler = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._on_before_fetch                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetcher</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">s.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">104</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">101 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._has_len = has_len(dataloader)                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">102 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">103 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">\"_PrefetchDataFetcher\"</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>104 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">105 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._has_len:                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">106 │   │   │   # ignore pre-fetching, it's not necessary</span>                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">107 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">fetcher</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">s.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">54</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 51 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 52 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #808000; text-decoration-color: #808000\">\"_DataFetcher\"</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 53 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.reset()                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 54 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataloader_iter = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dataloader)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 55 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 56 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 57 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__next__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; Any:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">com</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bined_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">284</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">281 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; Self:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">282 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span> = _SUPPORTED_MODES[<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._mode][<span style=\"color: #808000; text-decoration-color: #808000\">\"iterator\"</span>]                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">283 │   │   </span>iterator = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">cls</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.flattened)                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>284 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(iterator)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">285 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._iterator = iterator                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">286 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">287 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">com</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bined_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">75</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 72 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> out                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 73 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 74 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; Self:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 75 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>()                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 76 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._consumed = [<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>] * <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterables)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 77 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 78 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">com</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bined_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 33 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; Self:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterators = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(iterable) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterables]                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 37 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 38 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reset</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">com</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">bined_loader.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">35</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;listcomp&gt;</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 32 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">NotImplementedError</span>                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 33 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 34 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; Self:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 35 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterators = [<span style=\"color: #00ffff; text-decoration-color: #00ffff\">iter</span>(iterable) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> iterable <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.iterables]                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 36 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 37 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 38 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reset</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>) -&gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">442</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__iter__</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 439 │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._iterator._reset(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 440 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._iterator                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 441 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 442 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._get_iterator()                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 443 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 444 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 445 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_auto_collation</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">388</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_iterator</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 385 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _SingleProcessDataLoaderIter(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 386 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 387 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.check_worker_number_rationality()                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 388 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _MultiProcessingDataLoaderIter(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 389 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 390 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@property</span>                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 391 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">multiprocessing_context</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>):                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">dataloader.py</span>: <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1043</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1040 │   │   │   #     it started, so that we do not call .join() if program dies</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1041 │   │   │   #     before it starts, and __del__ tries to join but will get:</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1042 │   │   │   #     AssertionError: can only join a started process.</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1043 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>w.start()                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1044 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._index_queues.append(index_queue)                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1045 │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._workers.append(w)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1046 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">process.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">121</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">start</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">118 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">assert</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> _current_process._config.get(<span style=\"color: #808000; text-decoration-color: #808000\">'daemon'</span>), \\                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">119 │   │   │      </span><span style=\"color: #808000; text-decoration-color: #808000\">'daemonic processes are not allowed to have children'</span>                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120 │   │   </span>_cleanup()                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>121 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._popen = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._Popen(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>)                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._sentinel = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._popen.sentinel                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 │   │   # Avoid a refcycle if the target function holds an indirect</span>                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">124 │   │   # reference to the process object (see bpo-30775)</span>                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">224</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_Popen</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">221 │   </span>_start_method = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">222 │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@staticmethod</span>                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">223 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_Popen</span>(process_obj):                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>224 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _default_context.get_context().Process._Popen(process_obj)                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">225 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">226 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">DefaultContext</span>(BaseContext):                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">227 │   </span>Process = Process                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">context.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">277</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_Popen</span>      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">274 │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">@staticmethod</span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">275 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_Popen</span>(process_obj):                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">276 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">.popen_fork</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">import</span> Popen                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>277 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> Popen(process_obj)                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">278 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">279 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">SpawnProcess</span>(process.BaseProcess):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">280 │   │   </span>_start_method = <span style=\"color: #808000; text-decoration-color: #808000\">'spawn'</span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">popen_fork.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">19</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">16 │   │   </span>util._flush_std_streams()                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">17 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.returncode = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">18 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.finalizer = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>19 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._launch(process_obj)                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">20 │   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">21 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">duplicate_for_child</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fd):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">22 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> fd                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">popen_fork.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">70</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_launch</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">67 │   │   </span>code = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68 │   │   </span>parent_r, child_w = os.pipe()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">69 │   │   </span>child_r, parent_w = os.pipe()                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>70 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pid = os.fork()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">71 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.pid == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">72 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">73 │   │   │   │   </span>os.close(parent_r)                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OSError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span><span style=\"font-weight: bold\">]</span> Cannot allocate memory\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m16\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m\u001b[2m# set_module_requires_grad(mt.model, list(range(n_layer)), ATTN, True)\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m# trainer = pl.Trainer(**trainer_config, logger=WandbLogger(project='tune medqa', name='\u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0mtrainer = pl.Trainer(**trainer_config)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m16 trainer.fit(mt, train_dl)                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrain\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mer.py\u001b[0m:\u001b[94m520\u001b[0m in \u001b[92mfit\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 517 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 518 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 519 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 520 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 521 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 522 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 523 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mcall.\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mpy\u001b[0m:\u001b[94m44\u001b[0m in \u001b[92m_call_and_handle_interrupt\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 44 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   │   \u001b[0m_call_teardown_hook(trainer)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrain\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mer.py\u001b[0m:\u001b[94m559\u001b[0m in \u001b[92m_fit_impl\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 556 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_provided=\u001b[94mTrue\u001b[0m,                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 557 \u001b[0m\u001b[2m│   │   │   \u001b[0mmodel_connected=\u001b[96mself\u001b[0m.lightning_module \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m,                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 558 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 559 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._run(model, ckpt_path=ckpt_path)                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 560 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 561 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m.state.stopped                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 562 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.training = \u001b[94mFalse\u001b[0m                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrain\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mer.py\u001b[0m:\u001b[94m935\u001b[0m in \u001b[92m_run\u001b[0m                                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 932 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 933 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# RUN THE TRAINER\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 934 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 935 \u001b[2m│   │   \u001b[0mresults = \u001b[96mself\u001b[0m._run_stage()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 936 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 937 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# ----------------------------\u001b[0m                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 938 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# POST-Training CLEAN UP\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrain\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mer.py\u001b[0m:\u001b[94m978\u001b[0m in \u001b[92m_run_stage\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 975 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m isolate_rng():                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 976 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._run_sanity_check()                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 977 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.autograd.set_detect_anomaly(\u001b[96mself\u001b[0m._detect_anomaly):                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 978 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.fit_loop.run()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 979 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 980 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mUnexpected state \u001b[0m\u001b[33m{\u001b[0m\u001b[96mself\u001b[0m.state\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 981 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mfit_loo\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mp.py\u001b[0m:\u001b[94m201\u001b[0m in \u001b[92mrun\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m198 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m199 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m200 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_start()                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m201 \u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance()                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m202 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.on_advance_end()                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m203 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._restarting = \u001b[94mFalse\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m204 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mStopIteration\u001b[0m:                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mfit_loo\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mp.py\u001b[0m:\u001b[94m354\u001b[0m in \u001b[92madvance\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m351 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[96mself\u001b[0m._data_fetcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m352 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._data_fetcher.setup(combined_loader)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m353 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.trainer.profiler.profile(\u001b[33m\"\u001b[0m\u001b[33mrun_training_epoch\u001b[0m\u001b[33m\"\u001b[0m):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m354 \u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.epoch_loop.run(\u001b[96mself\u001b[0m._data_fetcher)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m355 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m356 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mon_advance_end\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m357 \u001b[0m\u001b[2m│   │   \u001b[0mtrainer = \u001b[96mself\u001b[0m.trainer                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mtrainin\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mg_epoch_loop.py\u001b[0m:\u001b[94m130\u001b[0m in \u001b[92mrun\u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m128 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mrun\u001b[0m(\u001b[96mself\u001b[0m, data_fetcher: _DataFetcher) -> \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m129 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.reset()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m130 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.on_run_start(data_fetcher)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m \u001b[96mself\u001b[0m.done:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.advance(data_fetcher)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mtrainin\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mg_epoch_loop.py\u001b[0m:\u001b[94m164\u001b[0m in \u001b[92mon_run_start\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.val_loop.batch_progress.total.reset()                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mon_run_start\u001b[0m(\u001b[96mself\u001b[0m, data_fetcher: _DataFetcher) -> \u001b[94mNone\u001b[0m:                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m164 \u001b[2m│   │   \u001b[0m\u001b[96miter\u001b[0m(data_fetcher)  \u001b[2m# creates the iterator inside the fetcher\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# add the previous `fetched` value to properly track `is_last_batch` with no pre\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m166 \u001b[0m\u001b[2m│   │   \u001b[0mdata_fetcher.fetched += \u001b[96mself\u001b[0m.batch_progress.current.ready                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m167 \u001b[0m\u001b[2m│   │   \u001b[0mdata_fetcher._start_profiler = \u001b[96mself\u001b[0m._on_before_fetch                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mfetcher\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33ms.py\u001b[0m:\u001b[94m104\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m101 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._has_len = has_len(dataloader)                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m102 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m103 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[33m\"\u001b[0m\u001b[33m_PrefetchDataFetcher\u001b[0m\u001b[33m\"\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m104 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__iter__\u001b[0m()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m105 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m._has_len:                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m106 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# ignore pre-fetching, it's not necessary\u001b[0m                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m107 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/loops/\u001b[0m\u001b[1;33mfetcher\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33ms.py\u001b[0m:\u001b[94m54\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 52 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[33m\"\u001b[0m\u001b[33m_DataFetcher\u001b[0m\u001b[33m\"\u001b[0m:                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 53 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.reset()                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 54 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.dataloader_iter = \u001b[96miter\u001b[0m(\u001b[96mself\u001b[0m.dataloader)                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 55 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 56 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 57 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__next__\u001b[0m(\u001b[96mself\u001b[0m) -> Any:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/\u001b[0m\u001b[1;33mcom\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mbined_loader.py\u001b[0m:\u001b[94m284\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m281 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> Self:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m282 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mcls\u001b[0m = _SUPPORTED_MODES[\u001b[96mself\u001b[0m._mode][\u001b[33m\"\u001b[0m\u001b[33miterator\u001b[0m\u001b[33m\"\u001b[0m]                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m283 \u001b[0m\u001b[2m│   │   \u001b[0miterator = \u001b[96mcls\u001b[0m(\u001b[96mself\u001b[0m.flattened)                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m284 \u001b[2m│   │   \u001b[0m\u001b[96miter\u001b[0m(iterator)                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m285 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._iterator = iterator                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m286 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m287 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/\u001b[0m\u001b[1;33mcom\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mbined_loader.py\u001b[0m:\u001b[94m75\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 72 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m out                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 73 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 74 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> Self:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 75 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__iter__\u001b[0m()                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 76 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._consumed = [\u001b[94mFalse\u001b[0m] * \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.iterables)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 77 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 78 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/\u001b[0m\u001b[1;33mcom\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mbined_loader.py\u001b[0m:\u001b[94m35\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 33 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> Self:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 35 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.iterators = [\u001b[96miter\u001b[0m(iterable) \u001b[94mfor\u001b[0m iterable \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.iterables]                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 37 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 38 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreset\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/pytorch_lightning/utilities/\u001b[0m\u001b[1;33mcom\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[1;33mbined_loader.py\u001b[0m:\u001b[94m35\u001b[0m in \u001b[92m<listcomp>\u001b[0m                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 32 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mNotImplementedError\u001b[0m                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 33 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 34 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__iter__\u001b[0m(\u001b[96mself\u001b[0m) -> Self:                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 35 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.iterators = [\u001b[96miter\u001b[0m(iterable) \u001b[94mfor\u001b[0m iterable \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.iterables]                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 36 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 37 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 38 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreset\u001b[0m(\u001b[96mself\u001b[0m) -> \u001b[94mNone\u001b[0m:                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m442\u001b[0m in \u001b[92m__iter__\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 439 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._iterator._reset(\u001b[96mself\u001b[0m)                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 440 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._iterator                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 441 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 442 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._get_iterator()                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 443 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 444 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 445 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_auto_collation\u001b[0m(\u001b[96mself\u001b[0m):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m388\u001b[0m in \u001b[92m_get_iterator\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 385 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _SingleProcessDataLoaderIter(\u001b[96mself\u001b[0m)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 386 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 387 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.check_worker_number_rationality()                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 388 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _MultiProcessingDataLoaderIter(\u001b[96mself\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 389 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 390 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@property\u001b[0m                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 391 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mmultiprocessing_context\u001b[0m(\u001b[96mself\u001b[0m):                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/site-packages/torch/utils/data/\u001b[0m\u001b[1;33mdataloader.py\u001b[0m: \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m1043\u001b[0m in \u001b[92m__init__\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1040 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m#     it started, so that we do not call .join() if program dies\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1041 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m#     before it starts, and __del__ tries to join but will get:\u001b[0m               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1042 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m#     AssertionError: can only join a started process.\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1043 \u001b[2m│   │   │   \u001b[0mw.start()                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1044 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._index_queues.append(index_queue)                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1045 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._workers.append(w)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m1046 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/\u001b[0m\u001b[1;33mprocess.py\u001b[0m:\u001b[94m121\u001b[0m in \u001b[92mstart\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m118 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94massert\u001b[0m \u001b[95mnot\u001b[0m _current_process._config.get(\u001b[33m'\u001b[0m\u001b[33mdaemon\u001b[0m\u001b[33m'\u001b[0m), \\                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m119 \u001b[0m\u001b[2m│   │   │      \u001b[0m\u001b[33m'\u001b[0m\u001b[33mdaemonic processes are not allowed to have children\u001b[0m\u001b[33m'\u001b[0m                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m120 \u001b[0m\u001b[2m│   │   \u001b[0m_cleanup()                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m121 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._popen = \u001b[96mself\u001b[0m._Popen(\u001b[96mself\u001b[0m)                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._sentinel = \u001b[96mself\u001b[0m._popen.sentinel                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Avoid a refcycle if the target function holds an indirect\u001b[0m                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m124 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# reference to the process object (see bpo-30775)\u001b[0m                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/\u001b[0m\u001b[1;33mcontext.py\u001b[0m:\u001b[94m224\u001b[0m in \u001b[92m_Popen\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m221 \u001b[0m\u001b[2m│   \u001b[0m_start_method = \u001b[94mNone\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m222 \u001b[0m\u001b[2m│   \u001b[0m\u001b[1;95m@staticmethod\u001b[0m                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m223 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_Popen\u001b[0m(process_obj):                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m224 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _default_context.get_context().Process._Popen(process_obj)                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m225 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m226 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mDefaultContext\u001b[0m(BaseContext):                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m227 \u001b[0m\u001b[2m│   \u001b[0mProcess = Process                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/\u001b[0m\u001b[1;33mcontext.py\u001b[0m:\u001b[94m277\u001b[0m in \u001b[92m_Popen\u001b[0m      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m274 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[1;95m@staticmethod\u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m275 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_Popen\u001b[0m(process_obj):                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m276 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96m.\u001b[0m\u001b[4;96mpopen_fork\u001b[0m \u001b[94mimport\u001b[0m Popen                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m277 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m Popen(process_obj)                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m278 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m279 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mSpawnProcess\u001b[0m(process.BaseProcess):                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m280 \u001b[0m\u001b[2m│   │   \u001b[0m_start_method = \u001b[33m'\u001b[0m\u001b[33mspawn\u001b[0m\u001b[33m'\u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/\u001b[0m\u001b[1;33mpopen_fork.py\u001b[0m:\u001b[94m19\u001b[0m in \u001b[92m__init__\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m16 \u001b[0m\u001b[2m│   │   \u001b[0mutil._flush_std_streams()                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m17 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.returncode = \u001b[94mNone\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m18 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.finalizer = \u001b[94mNone\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m19 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._launch(process_obj)                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m20 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m21 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mduplicate_for_child\u001b[0m(\u001b[96mself\u001b[0m, fd):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m22 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m fd                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/nvme/guoyiqiu/miniconda3/envs/hug42/lib/python3.8/multiprocessing/\u001b[0m\u001b[1;33mpopen_fork.py\u001b[0m:\u001b[94m70\u001b[0m in \u001b[92m_launch\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m67 \u001b[0m\u001b[2m│   │   \u001b[0mcode = \u001b[94m1\u001b[0m                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m68 \u001b[0m\u001b[2m│   │   \u001b[0mparent_r, child_w = os.pipe()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m69 \u001b[0m\u001b[2m│   │   \u001b[0mchild_r, parent_w = os.pipe()                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m70 \u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.pid = os.fork()                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m71 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.pid == \u001b[94m0\u001b[0m:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m72 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m73 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mos.close(parent_r)                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOSError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m12\u001b[0m\u001b[1m]\u001b[0m Cannot allocate memory\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_config = {\n",
    "    \"precision\": \"16-mixed\",\n",
    "    \"accelerator\": \"auto\",\n",
    "    \"devices\": [7],\n",
    "    \"enable_checkpointing\":False,\n",
    "    # 'accumulate_grad_batches': 8,\n",
    "    \"max_epochs\":20,\n",
    "}\n",
    "\n",
    "# mt.clear_hook()\n",
    "# mt.set_func('training_step', my_training_step)\n",
    "# freeze_all(mt.model)\n",
    "# set_module_requires_grad(mt.model, list(range(n_layer)), ATTN, True)\n",
    "# trainer = pl.Trainer(**trainer_config, logger=WandbLogger(project='tune medqa', name='litetune_5ep_vicuna7b'))\n",
    "trainer = pl.Trainer(**trainer_config)\n",
    "trainer.fit(mt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint('./lora_gpt2xl_counterfact_50ep.ckpt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
