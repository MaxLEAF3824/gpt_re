{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "from model.model_interface import LLM\n",
    "import torch.utils.data as tud\n",
    "from torch.utils.data import DataLoader\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "from utils.viz_tool import *\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llama_7b_local_dir = \"/nvme/guoyiqiu/coding/huggingface/my_models/llama-7b\"\n",
    "llm_config = {\n",
    "    \"model_name\": llama_7b_local_dir,\n",
    "    \"half\": True,\n",
    "}\n",
    "mt = LLM(**llm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.model.model.layers[0].mlp.up_proj.weight.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hook Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_config = {\n",
    "    \"retain_output\": True,\n",
    "    \"retain_input\": False,\n",
    "    \"edit_output\": None,\n",
    "    \"clone\": False,\n",
    "    \"detach\": False,\n",
    "    \"device\": \"cpu\"\n",
    "}\n",
    "\n",
    "n_layer = mt.model.config.num_hidden_layers\n",
    "# gpt2 config\n",
    "# blocks = mt.model.transformer.h\n",
    "# llama config\n",
    "blocks = mt.model.model.layers\n",
    "\n",
    "\n",
    "mt.clear_hook()\n",
    "for i in range(n_layer):\n",
    "    mt.add_hook(module=blocks[i],name=f\"block_{i}\", **hook_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz = 1\n",
    "\n",
    "from dataset.knowns import Knowns\n",
    "\n",
    "dst = Knowns(\"/nvme/guoyiqiu/coding/gpt_re/data\", mt.tokenizer)\n",
    "dl = DataLoader(dst, batch_size=bsz, collate_fn=dst.collate_fn)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = {\n",
    "    \"precision\" : \"16-mixed\",\n",
    "    \"accelerator\" : \"auto\",\n",
    "    \"devices\" : [5],\n",
    "}\n",
    "trainer = pl.Trainer(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.predict(mt, dl)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse Mean Residual Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blocks_mean_output = [[] for i in range(n_layer)]\n",
    "for idx, (input_ids, attention_mask, labels) in enumerate(dl):\n",
    "    seq_len = attention_mask.sum(dim=1).unsqueeze(-1).repeat(1,mt.model.config.hidden_size)\n",
    "    attention_mask = attention_mask.unsqueeze(-1).repeat(1,1,mt.model.config.hidden_size)\n",
    "    for i in range(n_layer):\n",
    "        output_i_idx = mt.hooks[f\"block_{i}\"].outputs[idx][0]\n",
    "        output_i_idx = output_i_idx * attention_mask.float()\n",
    "        output_i_idx = output_i_idx.sum(dim=1) / seq_len # [bsz, hidden_size] # compute mean\n",
    "        # output_i_idx = output_i_idx[:,-1,:] # [bsz, hidden_size] # use last\n",
    "        blocks_mean_output[i].append(output_i_idx)\n",
    "blocks_mean_output = [torch.vstack(b).mean(0) for b in blocks_mean_output]\n",
    "plotly_bar(\"Avg norm of layer output\", [torch.norm(b).item() for b in blocks_mean_output])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unembedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 125\n",
    "\n",
    "bi = idx // bsz\n",
    "i = idx - (idx // bsz) * bsz\n",
    "\n",
    "input_ids, attention_mask, labels = list(dl)[bi][0][i], list(dl)[bi][1][i], list(dl)[bi][2][i]\n",
    "outputs = [h.outputs[bi][0][i] for h in mt.hooks.values()]\n",
    "logits = res[bi]['logits'][i][-2] # last token is <\\s> so -2\n",
    "\n",
    "input_tokens = mt.tokenizer.decode(input_ids)\n",
    "prob, next_ids = torch.topk(F.softmax(logits.float(),dim=-1), 5)\n",
    "next_token = {mt.tokenizer.decode(t) : \"{:7f}\".format(p.item()) for p, t in zip(prob, next_ids)}\n",
    "\n",
    "print(f\"prompt: {input_tokens}\")\n",
    "print(f\"next token: {next_token}\")\n",
    "\n",
    "# mt.generate(input_tokens, max_new_tokens=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([[1, 2, 3],\n",
    "                 [4, 5, 6],\n",
    "                 [7, 8, 9]])\n",
    "\n",
    "# 添加辅助信息字典\n",
    "info_dict = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}\n",
    "\n",
    "# 创建customdata数组\n",
    "customdata = []\n",
    "for row in data:\n",
    "    customdata_row = []\n",
    "    for val in row:\n",
    "        customdata_row.append(info_dict)\n",
    "    customdata.append(customdata_row)\n",
    "\n",
    "trace = go.Heatmap(z=data, customdata=customdata, hovertemplate='x=%{x}<br>y=%{y}<br>customdata=%{customdata}')\n",
    "\n",
    "layout = go.Layout(title='Heatmap Example',\n",
    "                   xaxis=dict(title='X Axis'),\n",
    "                   yaxis=dict(title='Y Axis'))\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hug42",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "050f86f3b22edf7bc80fb626cbf8bb17cb45c28153f9cc5fe6a39a1c9f0fd115"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
