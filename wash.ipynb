{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取训练语料和NER结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir:  /home/cs/yangyuchen/guoyiqiu/kg_llm/data\n",
      "data_name:  medmcqa_dev\n",
      "读取数据集和NER结果文件...\n",
      "初步清洗NER结果...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951304deac394bd8b317647ecd5fa15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26826 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "被清洗的未知类别(999)实体数量: 1544，占比: 0.057556102288824275\n",
      "被清洗的非单词实体数量: 0，占比: 0.0\n",
      "初步清洗后的数据集: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_entities</th>\n",
       "      <th>input_entities_cid</th>\n",
       "      <th>output_entities</th>\n",
       "      <th>output_entities_cid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following is not true for myelina...</td>\n",
       "      <td>A</td>\n",
       "      <td>[myelinated nerve fibers, Impulse, myelinated ...</td>\n",
       "      <td>[CN33499808, CN00044749, CN02095548, CN0736878...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is not true about glome...</td>\n",
       "      <td>A</td>\n",
       "      <td>[glomerular capillaries, oncotic pressure, cap...</td>\n",
       "      <td>[CN00453049, CN00007663, CN00015232, CN0045865...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 29 yrs old woman with a pregnancy of 17 week...</td>\n",
       "      <td>C</td>\n",
       "      <td>[pregnancy, down syndrome, down syndrome, advi...</td>\n",
       "      <td>[CN00454003, CN00016551, CN00016551, CN0001799...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Axonal transport is: Options:A: Antegrade, B: ...</td>\n",
       "      <td>C</td>\n",
       "      <td>[Axonal transport]</td>\n",
       "      <td>[CN00473776]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low insulin to glucagon ratio is seen in all o...</td>\n",
       "      <td>A</td>\n",
       "      <td>[insulin, glucagon, Glycogen synthesis, Glycog...</td>\n",
       "      <td>[CN32853719, CN00117640, CN00056666, CN0000965...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>A study is to be conducted with regards to the...</td>\n",
       "      <td>A</td>\n",
       "      <td>[fat, expressed breast milk, coho]</td>\n",
       "      <td>[CN00506745, CN00150819, CN28173440]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>APGAR acronym stands for? Options:A: Activity,...</td>\n",
       "      <td>D</td>\n",
       "      <td>[APGAR, pulse pressure, grimace, respiration, ...</td>\n",
       "      <td>[CN00033786, CN00029530, CN00086647, CN3292265...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>Most commonly implicated drug for acute liver ...</td>\n",
       "      <td>A</td>\n",
       "      <td>[acute liver failure, Paracetamol, Valproate, ...</td>\n",
       "      <td>[CN00452947, CN32931003, CN00236867, CN0005756...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>A 9 year old boy has steroid dependent nephrot...</td>\n",
       "      <td>B</td>\n",
       "      <td>[steroid dependent nephrotic syndrome, cushing...</td>\n",
       "      <td>[CN00461839, CN13977028, CN33056928, CN0019686...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>Most common type of Non-Hodgkin's lymphoma in ...</td>\n",
       "      <td>A</td>\n",
       "      <td>[Non-Hodgkin's lymphoma, orbit, B-cell, T-cell...</td>\n",
       "      <td>[CN00039036, CN34406134, CN32870876, CN0058634...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4183 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input output   \n",
       "0     Which of the following is not true for myelina...      A  \\\n",
       "1     Which of the following is not true about glome...      A   \n",
       "2     A 29 yrs old woman with a pregnancy of 17 week...      C   \n",
       "3     Axonal transport is: Options:A: Antegrade, B: ...      C   \n",
       "4     Low insulin to glucagon ratio is seen in all o...      A   \n",
       "...                                                 ...    ...   \n",
       "4178  A study is to be conducted with regards to the...      A   \n",
       "4179  APGAR acronym stands for? Options:A: Activity,...      D   \n",
       "4180  Most commonly implicated drug for acute liver ...      A   \n",
       "4181  A 9 year old boy has steroid dependent nephrot...      B   \n",
       "4182  Most common type of Non-Hodgkin's lymphoma in ...      A   \n",
       "\n",
       "                                         input_entities   \n",
       "0     [myelinated nerve fibers, Impulse, myelinated ...  \\\n",
       "1     [glomerular capillaries, oncotic pressure, cap...   \n",
       "2     [pregnancy, down syndrome, down syndrome, advi...   \n",
       "3                                    [Axonal transport]   \n",
       "4     [insulin, glucagon, Glycogen synthesis, Glycog...   \n",
       "...                                                 ...   \n",
       "4178                 [fat, expressed breast milk, coho]   \n",
       "4179  [APGAR, pulse pressure, grimace, respiration, ...   \n",
       "4180  [acute liver failure, Paracetamol, Valproate, ...   \n",
       "4181  [steroid dependent nephrotic syndrome, cushing...   \n",
       "4182  [Non-Hodgkin's lymphoma, orbit, B-cell, T-cell...   \n",
       "\n",
       "                                     input_entities_cid output_entities   \n",
       "0     [CN33499808, CN00044749, CN02095548, CN0736878...              []  \\\n",
       "1     [CN00453049, CN00007663, CN00015232, CN0045865...              []   \n",
       "2     [CN00454003, CN00016551, CN00016551, CN0001799...              []   \n",
       "3                                          [CN00473776]              []   \n",
       "4     [CN32853719, CN00117640, CN00056666, CN0000965...              []   \n",
       "...                                                 ...             ...   \n",
       "4178               [CN00506745, CN00150819, CN28173440]              []   \n",
       "4179  [CN00033786, CN00029530, CN00086647, CN3292265...              []   \n",
       "4180  [CN00452947, CN32931003, CN00236867, CN0005756...              []   \n",
       "4181  [CN00461839, CN13977028, CN33056928, CN0019686...              []   \n",
       "4182  [CN00039036, CN34406134, CN32870876, CN0058634...              []   \n",
       "\n",
       "     output_entities_cid  \n",
       "0                     []  \n",
       "1                     []  \n",
       "2                     []  \n",
       "3                     []  \n",
       "4                     []  \n",
       "...                  ...  \n",
       "4178                  []  \n",
       "4179                  []  \n",
       "4180                  []  \n",
       "4181                  []  \n",
       "4182                  []  \n",
       "\n",
       "[4183 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "\n",
    "data_path = '/home/cs/yangyuchen/guoyiqiu/kg_llm/data/medmcqa_dev.json'\n",
    "ner_path = '/home/cs/yangyuchen/guoyiqiu/kg_llm/data/medmcqa_dev_bios_v2.2_release_eng.txt'\n",
    "\n",
    "data_dir = \"/\".join(data_path.split('/')[:-1])\n",
    "print('data_dir: ', data_dir)\n",
    "data_name = '.'.join(data_path.split('/')[-1].split('.')[:-1]) \n",
    "print('data_name: ', data_name)\n",
    "\n",
    "print(f\"读取数据集和NER结果文件...\")\n",
    "with open(ner_path, encoding='utf-8') as f:\n",
    "    ner_str = f.read()\n",
    "    f.close()\n",
    "\n",
    "ner_str = ner_str.replace('｜','|')\n",
    "with open(ner_path,'w') as f:\n",
    "    f.write(ner_str)\n",
    "    f.close()\n",
    "\n",
    "ner_df = pd.read_csv(ner_path, sep='|')\n",
    "ner_df['LINE, BEGIN, END'] = ner_df['LINE, BEGIN, END'].apply(lambda x: eval(str(x)))\n",
    "ner_df['LINE'] = ner_df['LINE, BEGIN, END'].apply(lambda x: x[0])\n",
    "ner_df['BEGIN, END'] = ner_df['LINE, BEGIN, END'].apply(lambda x: (x[1],x[2]))\n",
    "ner_df.drop('LINE, BEGIN, END', axis=1, inplace=True)\n",
    "\n",
    "data_df = pd.read_json(data_path)\n",
    "data_strs = open(data_path, encoding='utf-8').readlines()\n",
    "data_df['input_entities'] = data_df.apply(lambda x: [], axis=1)\n",
    "data_df['input_entities_cid'] = data_df.apply(lambda x: [], axis=1)\n",
    "data_df['output_entities'] = data_df.apply(lambda x: [], axis=1)\n",
    "data_df['output_entities_cid'] = data_df.apply(lambda x: [], axis=1)\n",
    "\n",
    "num_999 = 0\n",
    "num_not_word = 0\n",
    "print(f\"初步清洗NER结果...\")\n",
    "for row in tqdm(ner_df.itertuples(), total=ner_df.shape[0]):\n",
    "    j = row.LINE//4\n",
    "    real_str = data_strs[row.LINE][row[-1][0]:row[-1][1]]\n",
    "    neighbor_str = data_strs[row.LINE]\n",
    "    \n",
    "    if row.STY.startswith('999'):\n",
    "        num_999+=1\n",
    "        continue\n",
    "    if len(re.findall(f\"[^\\w]{re.escape(real_str)}[^\\w]\", neighbor_str))==0:\n",
    "        print('neighbor_str: ', neighbor_str)\n",
    "        num_not_word+=1\n",
    "        continue\n",
    "    if row.LINE%4 == 2:\n",
    "        data_df.loc[j]['input_entities'].append(real_str)\n",
    "        data_df.loc[j]['input_entities_cid'].append(row.CID)\n",
    "    else:\n",
    "        data_df.loc[j]['output_entities'].append(real_str)\n",
    "        data_df.loc[j]['output_entities_cid'].append(row.CID)\n",
    "\n",
    "json.dump(data_df.to_dict(orient='records'), open(f'{data_dir}/ner_results_{data_name}.json','w'),indent=4)\n",
    "print(f\"被清洗的未知类别(999)实体数量: {num_999}，占比: {num_999/ner_df.shape[0]}\")\n",
    "print(f\"被清洗的非单词实体数量: {num_not_word}，占比: {num_not_word/ner_df.shape[0]}\")\n",
    "print('初步清洗后的数据集: ')\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行TF-IDF清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取缓存的单词计数/home/cs/yangyuchen/guoyiqiu/kg_llm/data/wc_usmle_train.pkl...\n",
      "正在计算TF_IDF...\n",
      "TF_IDF阈值: 7 开始执行TF-IDF清洗... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53f6ec959576495d9579323049cf27e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "清洗了2836个实体类别\n",
      "TF-IDF清洗后, 实体总数剩余比例:  0.4173416013721426\n",
      "TF-IDF清洗后, 实体类别剩余比例: 0.9448817367306085\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import math\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import json\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'\n",
    "tqdm.pandas()\n",
    "\n",
    "corpus = [i.input + \" \" + i.output for i in data_df.itertuples()]\n",
    "all_e_list = [i.input_entities + i.output_entities for i in data_df.itertuples()]\n",
    "all_e =  list(set([e for es in all_e_list for e in es]))\n",
    "all_text = ' '.join(corpus)\n",
    "\n",
    "\n",
    "def wc(e):\n",
    "    return {e:len(re.findall(f\"[^\\w]{re.escape(e)}[^\\w]\", all_text))}\n",
    "\n",
    "if os.path.exists(f'{data_dir}/wc_{data_name}.pkl'):\n",
    "    print(f\"读取缓存的单词计数{data_dir}/wc_{data_name}.pkl...\")\n",
    "    count = pickle.load(open(f'{data_dir}/wc_{data_name}.pkl', 'rb'))\n",
    "else:\n",
    "    print(\"正在进行单词计数...\")\n",
    "    pool = Pool(cpu_count())\n",
    "    count = {}\n",
    "    for o in tqdm(pool.imap_unordered(wc, all_e), total=len(all_e)):\n",
    "        count.update(o)\n",
    "    pool.close()\n",
    "    pickle.dump(count, open(f'{data_dir}/wc_{data_name}.pkl', 'wb'))\n",
    "\n",
    "print(\"正在计算TF_IDF...\")\n",
    "idf = {e: math.log(len(corpus)/c) for e,c in count.items()}\n",
    "all_tf = [{e: len(re.findall(f\"{re.escape(e)}\", corpus[i])) for e in e_list} for i,e_list in enumerate(all_e_list)]\n",
    "all_tf_idf = [{e: tf[e] * idf[e] for e in tf} for tf in all_tf]\n",
    "\n",
    "def mean_e_tf_idf(all_tf_idf):\n",
    "    mean_e_tf_idf = {}\n",
    "    for tf_idf in all_tf_idf:\n",
    "        for e in tf_idf:\n",
    "            if e not in mean_e_tf_idf:\n",
    "                mean_e_tf_idf[e] = [tf_idf[e]]\n",
    "            else:\n",
    "                mean_e_tf_idf[e].append(tf_idf[e])\n",
    "    for e in mean_e_tf_idf:\n",
    "        mean_e_tf_idf[e] = sum(mean_e_tf_idf[e]) / len(mean_e_tf_idf[e])\n",
    "\n",
    "    df = pd.DataFrame(list(mean_e_tf_idf.keys()), columns=['e'])\n",
    "    df['tf_idf'] = df['e'].apply(lambda x: mean_e_tf_idf[x])\n",
    "    df.sort_values('tf_idf', ascending=False, inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "def wash(row):\n",
    "    new_input_entities = []\n",
    "    new_input_entities_cid = []\n",
    "    new_output_entities = []\n",
    "    new_output_entities_cid = []\n",
    "    new_tf_idf = {}\n",
    "    for e,cid in zip(row['input_entities'],row['input_entities_cid']):\n",
    "        if row['tf_idf'][e] > TF_IDF_THRESHOLD:\n",
    "            new_input_entities.append(e)\n",
    "            new_input_entities_cid.append(cid)\n",
    "            new_tf_idf[e] = row['tf_idf'][e]\n",
    "    for e,cid in zip(row['output_entities'],row['output_entities_cid']):\n",
    "        if row['tf_idf'][e] > TF_IDF_THRESHOLD:\n",
    "            new_output_entities.append(e)\n",
    "            new_output_entities_cid.append(cid)\n",
    "            new_tf_idf[e] = row['tf_idf'][e]\n",
    "    row['input_entities'] = new_input_entities\n",
    "    row['input_entities_cid'] = new_input_entities_cid\n",
    "    row['output_entities'] = new_output_entities\n",
    "    row['output_entities_cid'] = new_output_entities_cid\n",
    "    row['tf_idf'] = new_tf_idf\n",
    "    return row\n",
    "    \n",
    "data_df['tf_idf'] = all_tf_idf\n",
    "\n",
    "TF_IDF_THRESHOLD = 7\n",
    "print(f\"TF_IDF阈值: {TF_IDF_THRESHOLD} 开始执行TF-IDF清洗... \")\n",
    "new_data_df = data_df.progress_apply(wash, axis=1)\n",
    "json.dump(new_data_df.to_dict(orient='records'), open(f'{data_dir}/ner_results_{data_name}.json','w'), indent=4)\n",
    "\n",
    "new_e_tf_idf = mean_e_tf_idf(new_data_df['tf_idf'])\n",
    "old_e_tf_idf = mean_e_tf_idf(all_tf_idf)\n",
    "new_e = set(new_e_tf_idf['e'].tolist())\n",
    "old_e = set(old_e_tf_idf['e'].tolist())\n",
    "wash_e = old_e - new_e\n",
    "\n",
    "print(f\"清洗了{len(wash_e)}个实体类别\")\n",
    "# for e in wash_e:\n",
    "#     print(e)\n",
    "print(\"TF-IDF清洗后, 实体总数剩余比例: \", (new_data_df['input_entities'].apply(len).sum()+new_data_df['output_entities'].apply(len).sum()) / (data_df['input_entities'].apply(len).sum() + data_df['output_entities'].apply(len).sum()))\n",
    "print(\"TF-IDF清洗后, 实体类别剩余比例:\", mean_e_tf_idf(new_data_df['tf_idf'].tolist()).shape[0]/mean_e_tf_idf(all_tf_idf).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 执行Grounding并导出kg_dataset.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在读取知识图谱...\n",
      "正在构建知识图谱索引...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af9e4b4d0364b9fbe6e1d640effb82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35327128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "print(\"正在读取知识图谱...\")\n",
    "kg = pd.read_csv('data/bios_kg_with_def_detailed.csv')\n",
    "c2i = defaultdict(list)\n",
    "\n",
    "print(\"正在构建知识图谱索引...\")\n",
    "for row in tqdm(kg.itertuples(), total=kg.shape[0]):\n",
    "    c2i[row[4]].append(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在添加知识三元组...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a360140ce6c5414c8c7a0817fb1d24bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10178 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_entities</th>\n",
       "      <th>output_entities</th>\n",
       "      <th>input_triplets</th>\n",
       "      <th>output_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old pregnant woman at 22 weeks gesta...</td>\n",
       "      <td>E</td>\n",
       "      <td>[cranberry extract, gravid uterus]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[18182139, 18182140, 18182141], [18429743, 18...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 3-month-old baby died suddenly at night whil...</td>\n",
       "      <td>A</td>\n",
       "      <td>[death]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[285185]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A mother brings her 3-week-old infant to the p...</td>\n",
       "      <td>A</td>\n",
       "      <td>[feeding habits, ventral pancreatic bud, proxi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[11800904, 11800905], [16762920, 16762921, 16...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A pulmonary autopsy specimen from a 58-year-ol...</td>\n",
       "      <td>A</td>\n",
       "      <td>[pulmonary autopsy, acute hypoxic respiratory ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[22661828], [17896622], [235796, 644860, 6448...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 20-year-old woman presents with menorrhagia ...</td>\n",
       "      <td>E</td>\n",
       "      <td>[bruising, PT 12, PTT 43, Factor V Leiden, Lup...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[22110595], [21066621, 21066622, 21066623], [...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>A 60-year-old man presents to the emergency de...</td>\n",
       "      <td>B</td>\n",
       "      <td>[preceding symptoms, preserved ejection fracti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[17472335], [10934878, 10934879], [1346950, 1...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>A 45-year-old male with a 15-year history of d...</td>\n",
       "      <td>B</td>\n",
       "      <td>[renal impairment, sensitive test, renal impai...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35315253, 35315254, 35315255, 35315256, 3531...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10175</th>\n",
       "      <td>After receiving a positive newborn screening r...</td>\n",
       "      <td>B</td>\n",
       "      <td>[sweat test, DNA sequencing, base pair deletio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[362529, 18348081, 18348082, 18348083, 183480...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>A 25-year-old man comes to the office because ...</td>\n",
       "      <td>C</td>\n",
       "      <td>[point tenderness, shoulder, Branched-chain al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[26845955, 26845956, 26845957], [46416, 23295...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>A 26-year-old primigravid woman comes to the e...</td>\n",
       "      <td>D</td>\n",
       "      <td>[Transvaginal ultrasonography, fetal parts, la...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35314527, 35314528, 35314529, 35314530, 3531...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10178 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input output   \n",
       "0      A 23-year-old pregnant woman at 22 weeks gesta...      E  \\\n",
       "1      A 3-month-old baby died suddenly at night whil...      A   \n",
       "2      A mother brings her 3-week-old infant to the p...      A   \n",
       "3      A pulmonary autopsy specimen from a 58-year-ol...      A   \n",
       "4      A 20-year-old woman presents with menorrhagia ...      E   \n",
       "...                                                  ...    ...   \n",
       "10173  A 60-year-old man presents to the emergency de...      B   \n",
       "10174  A 45-year-old male with a 15-year history of d...      B   \n",
       "10175  After receiving a positive newborn screening r...      B   \n",
       "10176  A 25-year-old man comes to the office because ...      C   \n",
       "10177  A 26-year-old primigravid woman comes to the e...      D   \n",
       "\n",
       "                                          input_entities output_entities   \n",
       "0                     [cranberry extract, gravid uterus]              []  \\\n",
       "1                                                [death]              []   \n",
       "2      [feeding habits, ventral pancreatic bud, proxi...              []   \n",
       "3      [pulmonary autopsy, acute hypoxic respiratory ...              []   \n",
       "4      [bruising, PT 12, PTT 43, Factor V Leiden, Lup...              []   \n",
       "...                                                  ...             ...   \n",
       "10173  [preceding symptoms, preserved ejection fracti...              []   \n",
       "10174  [renal impairment, sensitive test, renal impai...              []   \n",
       "10175  [sweat test, DNA sequencing, base pair deletio...              []   \n",
       "10176  [point tenderness, shoulder, Branched-chain al...              []   \n",
       "10177  [Transvaginal ultrasonography, fetal parts, la...              []   \n",
       "\n",
       "                                          input_triplets output_triplets  \n",
       "0      [[18182139, 18182140, 18182141], [18429743, 18...              []  \n",
       "1                                             [[285185]]              []  \n",
       "2      [[11800904, 11800905], [16762920, 16762921, 16...              []  \n",
       "3      [[22661828], [17896622], [235796, 644860, 6448...              []  \n",
       "4      [[22110595], [21066621, 21066622, 21066623], [...              []  \n",
       "...                                                  ...             ...  \n",
       "10173  [[17472335], [10934878, 10934879], [1346950, 1...              []  \n",
       "10174  [[35315253, 35315254, 35315255, 35315256, 3531...              []  \n",
       "10175  [[362529, 18348081, 18348082, 18348083, 183480...              []  \n",
       "10176  [[26845955, 26845956, 26845957], [46416, 23295...              []  \n",
       "10177  [[35314527, 35314528, 35314529, 35314530, 3531...              []  \n",
       "\n",
       "[10178 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grounding(row):\n",
    "    new_input_entities = []\n",
    "    new_output_entities = []\n",
    "    new_input_entities_cid = []\n",
    "    new_output_entities_cid = []\n",
    "    input_triplets = []\n",
    "    output_triplets = []\n",
    "    max_t = 9999999999999\n",
    "    for e,cid in zip(row['input_entities'],row['input_entities_cid']):\n",
    "        if cid in c2i and len(c2i[cid]) <= max_t:\n",
    "            new_input_entities.append(e)\n",
    "            new_input_entities_cid.append(cid)\n",
    "            input_triplets.append(c2i[cid])\n",
    "    for e,cid in zip(row['output_entities'],row['output_entities_cid']):\n",
    "        if cid in c2i and len(c2i[cid]) <= max_t:\n",
    "            new_output_entities.append(e)\n",
    "            new_output_entities_cid.append(cid)\n",
    "            output_triplets.append(c2i[cid])\n",
    "    row['input_entities'] = new_input_entities\n",
    "    row['output_entities'] = new_output_entities\n",
    "    row['input_entities_cid'] = new_input_entities_cid\n",
    "    row['output_entities_cid'] = new_output_entities_cid\n",
    "    row['input_triplets'] = input_triplets\n",
    "    row['output_triplets'] = output_triplets\n",
    "    return row\n",
    "\n",
    "print(\"正在添加知识三元组...\")\n",
    "new_data_df = new_data_df.progress_apply(grounding, axis=1)\n",
    "kg_data_df = new_data_df.drop(['tf_idf','input_entities_cid','output_entities_cid'],axis=1,inplace=False)\n",
    "import json\n",
    "json.dump(kg_data_df.to_dict(orient='records'), open(f'{data_dir}/kg_{data_name}.json','w'),indent=4)\n",
    "kg_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_entities</th>\n",
       "      <th>output_entities</th>\n",
       "      <th>input_triplets</th>\n",
       "      <th>output_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>A 31-year-old G2P2 female at 40 weeks gestatio...</td>\n",
       "      <td>D</td>\n",
       "      <td>[Fetal heart tracing, variable decelerations, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[20692702, 20692703, 20692704, 20692705], [17...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>A 4-year-old boy is brought to the physician b...</td>\n",
       "      <td>D</td>\n",
       "      <td>[Enalapril therapy, Furosemide therapy, Anti-s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[28316168, 28316169], [12215050, 12215051, 12...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>A 37-year-old woman comes to the physician bec...</td>\n",
       "      <td>B</td>\n",
       "      <td>[white spots, D-xylose, Gluten-free diet, Panc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[325958, 363212, 15126349, 15126350, 15126351...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>A 37-year-old patient is being evaluated for i...</td>\n",
       "      <td>D</td>\n",
       "      <td>[involuntary movements, neuromediators, trinuc...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[76701, 9007766, 9007767, 9007768], [142281, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>A 3000-g (6.6-lb) female newborn is delivered ...</td>\n",
       "      <td>C</td>\n",
       "      <td>[auditory screening tests, Congenital parvovir...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[1857389, 1857390], [16465312, 16465313, 1646...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10020</th>\n",
       "      <td>A 29-year-old internal medicine resident prese...</td>\n",
       "      <td>E</td>\n",
       "      <td>[Schistosoma haematobium, Onchocerca volvulus,...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[181070], [8453394], [284370, 6615965, 661596...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>A 45-year-old woman presents to her primary ca...</td>\n",
       "      <td>C</td>\n",
       "      <td>[badminton, snuffbox, Nodules, Ulnar deviation...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[289004, 28518992, 28518993], [35839, 291383,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10071</th>\n",
       "      <td>A 24-day-old neonate is brought to the emergen...</td>\n",
       "      <td>C</td>\n",
       "      <td>[sick people, rouse, neonatal meningitis, empi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[151528], [22285, 28852735, 28852736], [69755...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10166</th>\n",
       "      <td>A 61-year-old man presents to his primary care...</td>\n",
       "      <td>B</td>\n",
       "      <td>[cocaine abuse, bilateral lung bases, Palpable...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[59943, 15143363, 15143364], [23788962, 23788...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>A 25-year-old man comes to the office because ...</td>\n",
       "      <td>C</td>\n",
       "      <td>[point tenderness, shoulder, Branched-chain al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[26845955, 26845956, 26845957], [46416, 23295...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input output   \n",
       "39     A 31-year-old G2P2 female at 40 weeks gestatio...      D  \\\n",
       "63     A 4-year-old boy is brought to the physician b...      D   \n",
       "71     A 37-year-old woman comes to the physician bec...      B   \n",
       "111    A 37-year-old patient is being evaluated for i...      D   \n",
       "134    A 3000-g (6.6-lb) female newborn is delivered ...      C   \n",
       "...                                                  ...    ...   \n",
       "10020  A 29-year-old internal medicine resident prese...      E   \n",
       "10026  A 45-year-old woman presents to her primary ca...      C   \n",
       "10071  A 24-day-old neonate is brought to the emergen...      C   \n",
       "10166  A 61-year-old man presents to his primary care...      B   \n",
       "10176  A 25-year-old man comes to the office because ...      C   \n",
       "\n",
       "                                          input_entities output_entities   \n",
       "39     [Fetal heart tracing, variable decelerations, ...              []  \\\n",
       "63     [Enalapril therapy, Furosemide therapy, Anti-s...              []   \n",
       "71     [white spots, D-xylose, Gluten-free diet, Panc...              []   \n",
       "111    [involuntary movements, neuromediators, trinuc...              []   \n",
       "134    [auditory screening tests, Congenital parvovir...              []   \n",
       "...                                                  ...             ...   \n",
       "10020  [Schistosoma haematobium, Onchocerca volvulus,...              []   \n",
       "10026  [badminton, snuffbox, Nodules, Ulnar deviation...              []   \n",
       "10071  [sick people, rouse, neonatal meningitis, empi...              []   \n",
       "10166  [cocaine abuse, bilateral lung bases, Palpable...              []   \n",
       "10176  [point tenderness, shoulder, Branched-chain al...              []   \n",
       "\n",
       "                                          input_triplets output_triplets  \n",
       "39     [[20692702, 20692703, 20692704, 20692705], [17...              []  \n",
       "63     [[28316168, 28316169], [12215050, 12215051, 12...              []  \n",
       "71     [[325958, 363212, 15126349, 15126350, 15126351...              []  \n",
       "111    [[76701, 9007766, 9007767, 9007768], [142281, ...              []  \n",
       "134    [[1857389, 1857390], [16465312, 16465313, 1646...              []  \n",
       "...                                                  ...             ...  \n",
       "10020  [[181070], [8453394], [284370, 6615965, 661596...              []  \n",
       "10026  [[289004, 28518992, 28518993], [35839, 291383,...              []  \n",
       "10071  [[151528], [22285, 28852735, 28852736], [69755...              []  \n",
       "10166  [[59943, 15143363, 15143364], [23788962, 23788...              []  \n",
       "10176  [[26845955, 26845956, 26845957], [46416, 23295...              []  \n",
       "\n",
       "[440 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_options(row):\n",
    "    option_text = row['input'].split(\"Options:\")[1]\n",
    "    option_text = option_text.replace(\" A: \",\"\").replace(\" B: \",\"##\").replace(\" C: \",\"##\").replace(\" D: \",\"##\").replace(\" E: \",\"##\")\n",
    "    row['options'] = option_text.split(\"##\")\n",
    "    return row\n",
    "kg_data_df_with_options = kg_data_df.apply(get_options, axis=1)\n",
    "\n",
    "def options_in_entities(row):\n",
    "    oine_num = 0\n",
    "    for option in row['options']:\n",
    "        for e in row['input_entities']:\n",
    "            if option == e:\n",
    "                oine_num+=1\n",
    "                break\n",
    "        \n",
    "    return oine_num\n",
    "kg_data_df=kg_data_df[kg_data_df_with_options.apply(options_in_entities,axis=1)==5]\n",
    "json.dump(kg_data_df.to_dict(orient='records'), open(f'{data_dir}/kg_{data_name}_440.json','w'),indent=4)\n",
    "kg_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化数据集统计信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\"/home/cs/yangyuchen/yushengliao/Medical_LLM/llama-7b-hf\")\n",
    "\n",
    "LEN_DEF = kg[kg['edge'] == \"has definition of \"].shape[0]\n",
    "\n",
    "def da(row):\n",
    "    row_da = pd.Series()\n",
    "    all_text = (row['input'] + row['output']).lower()\n",
    "    row_da['sent_token_num'] = len(tok(row['input']+row['output'])['input_ids'])\n",
    "    et = [(e,ts) for e,ts in zip(row['input_entities'] + row['output_entities'], row['input_triplets'] + row['output_triplets'])]\n",
    "    et = sorted(et, key=lambda x: -len(tok(x[0])['input_ids']))\n",
    "    row_da['e_num'] = len(et)\n",
    "    uni_ts = set([t for (e,ts) in et for t in ts])\n",
    "    row_da['uni_t_num'] = len(uni_ts)\n",
    "    row_da['def_t_num'] = len([t for t in uni_ts if t < LEN_DEF])\n",
    "    row_da['kg_t_num'] = row_da['uni_t_num'] - row_da['def_t_num']\n",
    "    kg_token_num = 0\n",
    "    e_counts = []\n",
    "    ts_token_num = []\n",
    "    for e,ts in et:\n",
    "        e_count = len(re.findall(f\"[^\\w]{re.escape(e.lower())}[^\\w]\", all_text))\n",
    "        e_counts.append(e_count)\n",
    "        all_text = re.sub(f\"[^\\w]{re.escape(e.lower())}[^\\w]\", '', all_text)\n",
    "        all_t_token_num = [len(tok(kg.iloc[t]['edge'] + kg.iloc[t]['target'])['input_ids']) + 1 for t in ts]\n",
    "        ts_token_num.append(sum(all_t_token_num))\n",
    "        kg_token_num += sum(all_t_token_num) * e_count\n",
    "    row_da['e_counts'] = e_counts\n",
    "    e_ts_num = [len(ts) for e,ts in et]\n",
    "    row_da['e_ts_num'] = e_ts_num\n",
    "    row_da['ts_token_num'] = ts_token_num\n",
    "    row_da['kg_token_num'] = kg_token_num       \n",
    "    return row_da\n",
    "\n",
    "def plot_series(series, title, xlabel, ylabel):\n",
    "    series.hist(bins=series.max(), range=(0, series.max()))\n",
    "    print(f\"average {xlabel} :{series.mean()}\")\n",
    "    plt.axvline(x=series.mean(), color='r', linestyle='--', )\n",
    "    plt.title(title)\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "data_da_df = kg_data_df.progress_apply(da, axis=1)\n",
    "\n",
    "plot_series(data_da_df['sent_token_num'], 'corpus length distribution', 'corpus length', 'frequency')\n",
    "plot_series(data_da_df['kg_token_num'], 'kg token length distribution', 'kg token length', 'frequency')\n",
    "plot_series(data_da_df['kg_token_num'] + data_da_df['sent_token_num'], 'corpus with all kg length distribution', 'corpus with all kg length', 'frequency')\n",
    "plot_series(data_da_df['e_num'], 'entity num each corpus distribution', 'entity num each corpus', 'frequency')\n",
    "plot_series(data_da_df['uni_t_num'], 'unique triplets num each corpus distribution', 'unique triplets num each corpus', 'frequency')\n",
    "plot_series(data_da_df['def_t_num'], 'definition triplets num each corpus distribution', 'definition triplets num each corpus', 'frequency')\n",
    "plot_series(data_da_df['kg_t_num'], 'kg triplets num each corpus distribution', 'kg triplets num each corpus', 'frequency')\n",
    "plot_series(data_da_df['e_counts'].apply(lambda x: max(x) if x else 0), 'max e_counts num each corpus distribution', 'max e_counts num each corpus', 'frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成COT推理数据集-训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>input_entities</th>\n",
       "      <th>output_entities</th>\n",
       "      <th>input_triplets</th>\n",
       "      <th>output_triplets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A 23-year-old pregnant woman at 22 weeks gesta...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "      <td>[cranberry extract, gravid uterus]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[18182139, 18182140, 18182141], [18429743, 18...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A 3-month-old baby died suddenly at night whil...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "      <td>[death]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[285185]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A mother brings her 3-week-old infant to the p...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "      <td>[feeding habits, ventral pancreatic bud, proxi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[11800904, 11800905], [16762920, 16762921, 16...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A pulmonary autopsy specimen from a 58-year-ol...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "      <td>[pulmonary autopsy, acute hypoxic respiratory ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[22661828], [17896622], [235796, 644860, 6448...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A 20-year-old woman presents with menorrhagia ...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "      <td>[bruising, PT 12, PTT 43, Factor V Leiden, Lup...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[22110595], [21066621, 21066622, 21066623], [...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>A 60-year-old man presents to the emergency de...</td>\n",
       "      <td>The answer is B</td>\n",
       "      <td>[preceding symptoms, preserved ejection fracti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[17472335], [10934878, 10934879], [1346950, 1...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10174</th>\n",
       "      <td>A 45-year-old male with a 15-year history of d...</td>\n",
       "      <td>The answer is B</td>\n",
       "      <td>[renal impairment, sensitive test, renal impai...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35315253, 35315254, 35315255, 35315256, 3531...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10175</th>\n",
       "      <td>After receiving a positive newborn screening r...</td>\n",
       "      <td>The answer is B</td>\n",
       "      <td>[sweat test, DNA sequencing, base pair deletio...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[362529, 18348081, 18348082, 18348083, 183480...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10176</th>\n",
       "      <td>A 25-year-old man comes to the office because ...</td>\n",
       "      <td>The answer is C</td>\n",
       "      <td>[point tenderness, shoulder, Branched-chain al...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[26845955, 26845956, 26845957], [46416, 23295...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10177</th>\n",
       "      <td>A 26-year-old primigravid woman comes to the e...</td>\n",
       "      <td>The answer is D</td>\n",
       "      <td>[Transvaginal ultrasonography, fetal parts, la...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35314527, 35314528, 35314529, 35314530, 3531...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20356 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   input   \n",
       "0      A 23-year-old pregnant woman at 22 weeks gesta...  \\\n",
       "1      A 3-month-old baby died suddenly at night whil...   \n",
       "2      A mother brings her 3-week-old infant to the p...   \n",
       "3      A pulmonary autopsy specimen from a 58-year-ol...   \n",
       "4      A 20-year-old woman presents with menorrhagia ...   \n",
       "...                                                  ...   \n",
       "10173  A 60-year-old man presents to the emergency de...   \n",
       "10174  A 45-year-old male with a 15-year history of d...   \n",
       "10175  After receiving a positive newborn screening r...   \n",
       "10176  A 25-year-old man comes to the office because ...   \n",
       "10177  A 26-year-old primigravid woman comes to the e...   \n",
       "\n",
       "                                                  output   \n",
       "0      The related knowledge of the medical entities ...  \\\n",
       "1      The related knowledge of the medical entities ...   \n",
       "2      The related knowledge of the medical entities ...   \n",
       "3      The related knowledge of the medical entities ...   \n",
       "4      The related knowledge of the medical entities ...   \n",
       "...                                                  ...   \n",
       "10173                                    The answer is B   \n",
       "10174                                    The answer is B   \n",
       "10175                                    The answer is B   \n",
       "10176                                    The answer is C   \n",
       "10177                                    The answer is D   \n",
       "\n",
       "                                          input_entities output_entities   \n",
       "0                     [cranberry extract, gravid uterus]              []  \\\n",
       "1                                                [death]              []   \n",
       "2      [feeding habits, ventral pancreatic bud, proxi...              []   \n",
       "3      [pulmonary autopsy, acute hypoxic respiratory ...              []   \n",
       "4      [bruising, PT 12, PTT 43, Factor V Leiden, Lup...              []   \n",
       "...                                                  ...             ...   \n",
       "10173  [preceding symptoms, preserved ejection fracti...              []   \n",
       "10174  [renal impairment, sensitive test, renal impai...              []   \n",
       "10175  [sweat test, DNA sequencing, base pair deletio...              []   \n",
       "10176  [point tenderness, shoulder, Branched-chain al...              []   \n",
       "10177  [Transvaginal ultrasonography, fetal parts, la...              []   \n",
       "\n",
       "                                          input_triplets output_triplets  \n",
       "0      [[18182139, 18182140, 18182141], [18429743, 18...              []  \n",
       "1                                             [[285185]]              []  \n",
       "2      [[11800904, 11800905], [16762920, 16762921, 16...              []  \n",
       "3      [[22661828], [17896622], [235796, 644860, 6448...              []  \n",
       "4      [[22110595], [21066621, 21066622, 21066623], [...              []  \n",
       "...                                                  ...             ...  \n",
       "10173  [[17472335], [10934878, 10934879], [1346950, 1...              []  \n",
       "10174  [[35315253, 35315254, 35315255, 35315256, 3531...              []  \n",
       "10175  [[362529, 18348081, 18348082, 18348083, 183480...              []  \n",
       "10176  [[26845955, 26845956, 26845957], [46416, 23295...              []  \n",
       "10177  [[35314527, 35314528, 35314529, 35314530, 3531...              []  \n",
       "\n",
       "[20356 rows x 6 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "COT_INPUT_PROMPT = \"{INPUT} The medical entities in the text include: {ENTITIES}.\"\n",
    "COT_OUTPUT_PROMPT = \"The related knowledge of the medical entities include: {KNOWLEDGE}\\n\"\n",
    "COT2_OUTPUT_PROMPT = \"The answer is {ANSWER}\"\n",
    "\n",
    "def cot_step1(row):\n",
    "    new_row = row.copy()\n",
    "    ENTITIES = ', '.join(row['input_entities'])\n",
    "    KNOWLEDGE = ''\n",
    "    for e,ts in zip(row['input_entities'],row['input_triplets']):\n",
    "        for tid in ts:\n",
    "            know = kg.iloc[tid]\n",
    "            KNOWLEDGE += f\"{e} {know['edge']} {know['target']}; \"\n",
    "    ANSWER = row['output'].strip()\n",
    "    new_row['input'] = COT_INPUT_PROMPT.format(INPUT=row['input'], ENTITIES=ENTITIES)\n",
    "    new_row['output'] = COT_OUTPUT_PROMPT.format(KNOWLEDGE=KNOWLEDGE)\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "def cot_step2(row):\n",
    "    new_row = row.copy()\n",
    "    ENTITIES = ', '.join(row['input_entities'])\n",
    "    KNOWLEDGE = ''\n",
    "    for e,ts in zip(row['input_entities'],row['input_triplets']):\n",
    "        for tid in ts:\n",
    "            know = kg.iloc[tid]\n",
    "            KNOWLEDGE += f\"{e} {know['edge']} {know['target']}; \"\n",
    "    ANSWER = row['output'].strip()\n",
    "    new_row['input'] = COT_INPUT_PROMPT.format(INPUT=row['input'], ENTITIES=ENTITIES) + COT_OUTPUT_PROMPT.format(KNOWLEDGE=KNOWLEDGE)\n",
    "    new_row['output'] = COT2_OUTPUT_PROMPT.format(ANSWER=ANSWER)\n",
    "    \n",
    "    return new_row\n",
    "\n",
    "    \n",
    "cot_kg_out_data_df = pd.concat([kg_data_df.apply(cot_step1, axis=1), kg_data_df.apply(cot_step2, axis=1)])\n",
    "json.dump(cot_kg_out_data_df.to_dict('records'), open(f'{data_dir}/cot_kg_{data_name}.json','w'), indent=4)\n",
    "cot_kg_out_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成COT推理数据集-测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which of the following is not true for myelina...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Which of the following is not true about glome...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A 29 yrs old woman with a pregnancy of 17 week...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Axonal transport is: Options:A: Antegrade, B: ...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Low insulin to glucagon ratio is seen in all o...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4178</th>\n",
       "      <td>A study is to be conducted with regards to the...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4179</th>\n",
       "      <td>APGAR acronym stands for? Options:A: Activity,...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4180</th>\n",
       "      <td>Most commonly implicated drug for acute liver ...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4181</th>\n",
       "      <td>A 9 year old boy has steroid dependent nephrot...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4182</th>\n",
       "      <td>Most common type of Non-Hodgkin's lymphoma in ...</td>\n",
       "      <td>The related knowledge of the medical entities ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4183 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  input   \n",
       "0     Which of the following is not true for myelina...  \\\n",
       "1     Which of the following is not true about glome...   \n",
       "2     A 29 yrs old woman with a pregnancy of 17 week...   \n",
       "3     Axonal transport is: Options:A: Antegrade, B: ...   \n",
       "4     Low insulin to glucagon ratio is seen in all o...   \n",
       "...                                                 ...   \n",
       "4178  A study is to be conducted with regards to the...   \n",
       "4179  APGAR acronym stands for? Options:A: Activity,...   \n",
       "4180  Most commonly implicated drug for acute liver ...   \n",
       "4181  A 9 year old boy has steroid dependent nephrot...   \n",
       "4182  Most common type of Non-Hodgkin's lymphoma in ...   \n",
       "\n",
       "                                                 output  \n",
       "0     The related knowledge of the medical entities ...  \n",
       "1     The related knowledge of the medical entities ...  \n",
       "2     The related knowledge of the medical entities ...  \n",
       "3     The related knowledge of the medical entities ...  \n",
       "4     The related knowledge of the medical entities ...  \n",
       "...                                                 ...  \n",
       "4178  The related knowledge of the medical entities ...  \n",
       "4179  The related knowledge of the medical entities ...  \n",
       "4180  The related knowledge of the medical entities ...  \n",
       "4181  The related knowledge of the medical entities ...  \n",
       "4182  The related knowledge of the medical entities ...  \n",
       "\n",
       "[4183 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "COT_INPUT_PROMPT = \"{INPUT} The medical entities in the text include: {ENTITIES}.\"\n",
    "COT_OUTPUT_PROMPT = \"The related knowledge of the medical entities include: {KNOWLEDGE}\\n\"\n",
    "COT2_OUTPUT_PROMPT = \"The answer is {ANSWER}\"\n",
    "\n",
    "def cot_step12(row):\n",
    "    new_row = pd.Series()\n",
    "    ENTITIES = ', '.join(row['input_entities'])\n",
    "    KNOWLEDGE = ''\n",
    "    for e,ts in zip(row['input_entities'],row['input_triplets']):\n",
    "        for tid in ts:\n",
    "            know = kg.iloc[tid]\n",
    "            KNOWLEDGE += f\"{e} {know['edge']} {know['target']}; \"\n",
    "    ANSWER = row['output'].strip()\n",
    "    new_row['input'] = COT_INPUT_PROMPT.format(INPUT=row['input'], ENTITIES=ENTITIES)\n",
    "    new_row['output'] = COT_OUTPUT_PROMPT.format(KNOWLEDGE=KNOWLEDGE) + COT2_OUTPUT_PROMPT.format(ANSWER=ANSWER)\n",
    "    return new_row\n",
    "\n",
    "cot_kg_out_data_df = kg_data_df.apply(cot_step12, axis=1)\n",
    "json.dump(cot_kg_out_data_df.to_dict('records'), open(f'{data_dir}/cot_kg_{data_name}.json','w'), indent=4)\n",
    "cot_kg_out_data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成混合triplets数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ets = {}\n",
    "for row in kg_data_df.itertuples():\n",
    "    es = row.input_entities + row.output_entities\n",
    "    tss = row.input_triplets + row.output_triplets\n",
    "    for (e,ts) in zip(es,tss):\n",
    "        all_ets[e] = ts\n",
    "all_triplets = []\n",
    "for e,ts in all_ets.items():\n",
    "    for t in ts:\n",
    "        all_triplets.append(dict(input=f\"{e.strip()} {kg.iloc[t]['edge'].strip()}\", output=f\"{kg.iloc[t]['target'].strip()}\"))\n",
    "\n",
    "triplets_df = pd.DataFrame(all_triplets)\n",
    "data_df_with_tri = pd.concat([kg_data_df.drop(['input_entities','output_entities','input_triplets','output_triplets'], axis=1, inplace=False), triplets_df], axis=0)\n",
    "json.dump(data_df_with_tri.to_dict(orient='records'),open(f\"{data_dir}/tri_{data_name}.json\",'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(triplets_df.to_dict(orient='records'),open(f\"{data_dir}/tri_440.json\",'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "all_targets = set()\n",
    "for e,ts in all_ets.items():\n",
    "    for t in ts:\n",
    "        all_targets.add(kg.iloc[t]['target'].strip())\n",
    "sr2t = {}\n",
    "for triplet in all_triplets:\n",
    "    sr2t[triplet['input']] = [triplet['output']] + sr2t.get(triplet['input']) if sr2t.get(triplet['input'],False) else [triplet['output']]\n",
    "\n",
    "all_choices = []\n",
    "for sr,t in sr2t.items():\n",
    "    correct_ops = random.sample(t,min(3,len(t)))\n",
    "    wrong_ops = random.sample(list(all_targets - set(t)),5-len(correct_ops))\n",
    "    all_ops = correct_ops + wrong_ops\n",
    "    random.shuffle(all_ops)\n",
    "    op_str = \"\"\n",
    "    output = \"\"\n",
    "    for idx,op in zip(['A','B','C','D','E'],all_ops):\n",
    "        op_str += f\"{idx}: {op};\"\n",
    "        if op in correct_ops:\n",
    "            output += f\"{idx}: {op};\"\n",
    "    all_choices.append(dict(input=f\"Question: {sr}? Options: {op_str} The correct answer is\", output=output))\n",
    "train_ratio = 0.4\n",
    "train_choices = all_choices[:int(len(all_choices)*train_ratio)]\n",
    "test_choices = all_choices[int(len(all_choices)*train_ratio):]\n",
    "json.dump(train_choices,open(f\"{data_dir}/tri_multi_choice_440_train.json\",'w'), indent=4)\n",
    "json.dump(test_choices,open(f\"{data_dir}/tri_multi_choice_440_test.json\",'w'), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phyllodes-like tumor has definition of</td>\n",
       "      <td>medical condition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>estradiol substitution may treat</td>\n",
       "      <td>rec anorexia nervosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>estradiol substitution may treat</td>\n",
       "      <td>ovarian function insufficiency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>estradiol substitution may treat</td>\n",
       "      <td>pituitary insufficiencies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>estradiol substitution may treat</td>\n",
       "      <td>silent anovulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11454</th>\n",
       "      <td>stomach adenocarcinoma tumor is a</td>\n",
       "      <td>cancers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11455</th>\n",
       "      <td>thyroid's left lobe is a</td>\n",
       "      <td>endocrine and exocrine glands</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11456</th>\n",
       "      <td>thyroid's left lobe is a</td>\n",
       "      <td>thyroidium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11457</th>\n",
       "      <td>urinary stress urinary incontinence is a</td>\n",
       "      <td>kidney and-urine related disorders</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11458</th>\n",
       "      <td>retas has definition of</td>\n",
       "      <td>group of chemical compounds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11459 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input   \n",
       "0        phyllodes-like tumor has definition of  \\\n",
       "1              estradiol substitution may treat   \n",
       "2              estradiol substitution may treat   \n",
       "3              estradiol substitution may treat   \n",
       "4              estradiol substitution may treat   \n",
       "...                                         ...   \n",
       "11454         stomach adenocarcinoma tumor is a   \n",
       "11455                  thyroid's left lobe is a   \n",
       "11456                  thyroid's left lobe is a   \n",
       "11457  urinary stress urinary incontinence is a   \n",
       "11458                   retas has definition of   \n",
       "\n",
       "                                   output  \n",
       "0                       medical condition  \n",
       "1                    rec anorexia nervosa  \n",
       "2          ovarian function insufficiency  \n",
       "3               pituitary insufficiencies  \n",
       "4                      silent anovulation  \n",
       "...                                   ...  \n",
       "11454                             cancers  \n",
       "11455       endocrine and exocrine glands  \n",
       "11456                          thyroidium  \n",
       "11457  kidney and-urine related disorders  \n",
       "11458         group of chemical compounds  \n",
       "\n",
       "[11459 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "triplets_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_llm_gyq",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
